{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program to scrape various websites for data related to the Mission to Mars \n",
    "# and displays the information in a single HTML page. \n",
    "\n",
    "# Import the dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as r\n",
    "from pprint import pprint\n",
    "from splinter import Browser\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape news data from Mars website - https://mars.nasa.gov/news/\n",
    "# get the response for the url to create a html object\n",
    "url = \"https://mars.nasa.gov/news/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the web page and get the title and the article summary \n",
    "# time to use splinter to automate \n",
    "# input just the filename if the .exe is in the same folder esle the full path\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# open the url in splinter browser\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the html page from the browser using browser.html and save it using soup\n",
    "soup = BeautifulSoup(browser.html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asteroids, Hydrogen Make Great Recipe for Life on Mars\n",
      "Laser blasts in lab tests suggest asteroid bombardment could have provided key ingredients for life on ancient Mars.\n"
     ]
    }
   ],
   "source": [
    "# # Let's create empty lists\n",
    "# news_titles = []\n",
    "# news_summaries = []\n",
    "# Loop through the page to find all the titles and articles\n",
    "news_title = soup.find('div', class_='content_title').text.strip()\n",
    "news_summary = soup.find('div', class_='article_teaser_body').text.strip()\n",
    "\n",
    "print(news_title)\n",
    "print(news_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the featured  image from nasa website - JPL Mars Space Images - Featured Image\n",
    "jpl_base_url = \"https://www.jpl.nasa.gov/\"\n",
    "url_search = \"spaceimages/?search=&category=Mars\" \n",
    "\n",
    "# complete the url \n",
    "jpl_url = f\"{jpl_base_url}{url_search}\"\n",
    "\n",
    "# open the url in splinter browser\n",
    "browser.visit(jpl_url)\n",
    "\n",
    "# get the html page from the browser using browser.html and save it using soup\n",
    "soup = BeautifulSoup(browser.html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov//spaceimages/images/wallpaper/PIA17793-1920x1200.jpg\n"
     ]
    }
   ],
   "source": [
    "# retreive the image url from the homepage\n",
    "image_container = soup.find('article', class_=\"carousel_item\")\n",
    "\n",
    "# save the attributes to retrieve the url from the style attribute of article tag\n",
    "image_cont_attrs = image_container.attrs\n",
    "\n",
    "#  get the style attr values\n",
    "image_style = image_cont_attrs['style']\n",
    "# print(image_cont_attrs['style'])\n",
    "\n",
    "# use regex to retrieve the url from style attr\n",
    "text = image_style\n",
    "pattern = \"background-image: url\\(\\'(.*)\\'\\);\"\n",
    "x = re.search(pattern, text) \n",
    "\n",
    "# get the matched value with group command\n",
    "featured_image_url = x.group(1)\n",
    "\n",
    "# append the base url \n",
    "featured_image_url =  f\"{jpl_base_url}{featured_image_url}\"\n",
    "\n",
    "print(featured_image_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the mars weather website for their latest tweet\n",
    "twitter_url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "\n",
    "# open the url in splinter browser\n",
    "browser.visit(twitter_url)\n",
    "\n",
    "# get the html page from the browser using browser.html and save it using soup\n",
    "soup = BeautifulSoup(browser.html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InSight sol 115 (2019-03-24) low -96.0ºC (-140.7ºF) high -15.5ºC (4.1ºF)\\npressure at 7.30 hPapic.twitter.com/01vh3kQISH'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retreive the weather tweet\n",
    "mars_weather = soup.find('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text.strip()\n",
    "\n",
    "mars_weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                      0                              1\n",
      "0  Equatorial Diameter:                       6,792 km\n",
      "1       Polar Diameter:                       6,752 km\n",
      "2                 Mass:  6.42 x 10^23 kg (10.7% Earth)\n",
      "3                Moons:            2 (Phobos & Deimos)\n",
      "4       Orbit Distance:       227,943,824 km (1.52 AU)\n",
      "5         Orbit Period:           687 days (1.9 years)\n",
      "6  Surface Temperature:                  -153 to 20 °C\n",
      "7         First Record:              2nd millennium BC\n",
      "8          Recorded By:           Egyptian astronomers]\n",
      "('<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: '\n",
      " 'right;\">      <th>Equatorial Diameter:</th>      <th>Polar '\n",
      " 'Diameter:</th>      <th>Mass:</th>      <th>Moons:</th>      <th>Orbit '\n",
      " 'Distance:</th>      <th>Orbit Period:</th>      <th>Surface '\n",
      " 'Temperature:</th>      <th>First Record:</th>      <th>Recorded By:</th>    '\n",
      " '</tr>  </thead>  <tbody>    <tr>      <td>6,792 km</td>      <td>6,752 '\n",
      " 'km</td>      <td>6.42 x 10^23 kg (10.7% Earth)</td>      <td>2 (Phobos &amp; '\n",
      " 'Deimos)</td>      <td>227,943,824 km (1.52 AU)</td>      <td>687 days (1.9 '\n",
      " 'years)</td>      <td>-153 to 20 °C</td>      <td>2nd millennium BC</td>      '\n",
      " '<td>Egyptian astronomers</td>    </tr>  </tbody></table>')\n"
     ]
    }
   ],
   "source": [
    "# scrape the mars facts website table contents using Pandas\n",
    "mars_facts_url = 'https://space-facts.com/mars/'\n",
    "table = pd.read_html(mars_facts_url)\n",
    "\n",
    "print(table)\n",
    "\n",
    "# convert the returned list to a df\n",
    "mars_facts_df = table[0]\n",
    "\n",
    "\n",
    "# convert the df to a html table by transposing\n",
    "mars_facts_df.columns = [\"Column Name\", \"Value\"]\n",
    "mars_facts_df = mars_facts_df.set_index(\"Column Name\").T\n",
    "\n",
    "# Convert dataframe into html table\n",
    "mars_facts_html = mars_facts_df.to_html(index = False)\n",
    "\n",
    "# strip unwanted newlines from html table\n",
    "mars_facts_html = mars_facts_html.replace('\\n', '')\n",
    "\n",
    "\n",
    "pprint(mars_facts_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Cerberus Hemisphere Enhanced',\n",
      "  'urls': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'},\n",
      " {'title': 'Schiaparelli Hemisphere Enhanced',\n",
      "  'urls': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'},\n",
      " {'title': 'Syrtis Major Hemisphere Enhanced',\n",
      "  'urls': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'},\n",
      " {'title': 'Valles Marineris Hemisphere Enhanced',\n",
      "  'urls': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "# scrape the USGS Astrogeology site to obtain high resolution images for each of Mar's hemispheres.\n",
    "usgs_astro_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "\n",
    "# base url \n",
    "usgs_base_url = \"https://astrogeology.usgs.gov\"\n",
    "\n",
    "# open the url in splinter browser\n",
    "browser.visit(usgs_astro_url)\n",
    "\n",
    "# get the html page from the browser using browser.html and save it using soup\n",
    "soup = BeautifulSoup(browser.html, \"html.parser\")\n",
    "\n",
    "# creating an empty list to store the image urls \n",
    "hemisphere_img_urls = []\n",
    "\n",
    "# retreive the html tag and the urls\n",
    "hemisphere_results = soup.find_all('div', class_='description')\n",
    "# hemisphere_results\n",
    "\n",
    "# Loop through the results scrape the image url and title to append to the hemisphere_img_urls array\n",
    "for result in hemisphere_results:\n",
    "    title = result.find('h3').text.strip()\n",
    "    image_url = result.find('a')['href']\n",
    "    image_full_url = usgs_base_url + image_url\n",
    "    browser.visit(image_full_url)    \n",
    "    soup = BeautifulSoup(browser.html, \"html.parser\")\n",
    "    image_downloads = soup.find('div', class_='downloads')\n",
    "    full_image_url = image_downloads.find('a')['href']\n",
    "    hemisphere_img_urls.append({\"title\" : title, \"urls\": full_image_url})\n",
    "\n",
    "# Print the array\n",
    "pprint(hemisphere_img_urls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
